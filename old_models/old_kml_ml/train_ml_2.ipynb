{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 21:05:11,824\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-05-09 21:05:12,276\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "from ray import tune\n",
    "\n",
    "print(os.cpu_count())\n",
    "\n",
    "# workloads = [\"readseq\"]#, \"readrandomwriterandom\", \"mixgraph\", \"updaterandom\"] #[\"fileserver\", \"mixgraph\", \"oltp\", \"rwrandom\", \"readseq\", \"readwhilewriting\", \"varmail\", \"webserver\"]\n",
    "\n",
    "# accuracy as comparison of distribuitions\n",
    "# comparitive analysis against table base[HP], cart model[CMU], decision tree,\n",
    "# \n",
    "# -Plan-\n",
    "# Send decision tree graph\n",
    "# let's put latency in the buckets and predict the buckets\n",
    "# - powers of 2\n",
    "# - ?\n",
    "# differnt hw's\n",
    "    # mq-deadline ? setting all deadlines with predictions\n",
    "    # cache the I/O?\n",
    "    # accuracy is based not the class of buckets how far from correct bucket\n",
    "\n",
    "############### FEATURES ##################\n",
    "# 0. issue time to driver - inter-arrival time use it - time diff between two consecutive accesses\n",
    "# 1. operation type\n",
    "# 2. abs(LBA diffs)\n",
    "# 3. time diff between completions\n",
    "# 4. tag\n",
    "# 5. size - length of the I/O operation\n",
    "# 6. queue size\n",
    "# 7. Latency\n",
    "\n",
    "#-> Backtrack the decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]=\"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "workloads = [\"readseq0\", \"readseq1\", \"readseq2\", \"readseq3\", \"readwhilewriting0\", \"readwhilewriting1\", \"readreverse0\", \"readrandomwriterandom0\", \"readrandom0\", \"mixgraph0\", \"fillseq0\", \"fillseq1\", \"fill100k0\", \"fill100k1\"]\n",
    "config = {\"lr\" : 0.01, \"momentum\" : 0.90}\n",
    "num_epoch = 50\n",
    "do_binary_classification = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {}\n",
    "for w in workloads:\n",
    "    # print(\"reading data for\", w)\n",
    "    data = np.loadtxt(\"data/\" + w + \".csv\",\n",
    "                      dtype=np.double, skiprows=1, delimiter=\",\")\n",
    "    experiments[w] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = experiments[workloads[0]]\n",
    "\n",
    "# duplicate data\n",
    "for i in range(len(workloads)):\n",
    "    data_temp = experiments[workloads[i]]\n",
    "    while len(data_temp) < 160000:\n",
    "        data_temp = np.concatenate((data_temp, experiments[workloads[i]]), axis=0)\n",
    "    data_all = np.concatenate((data_all, data_temp), axis=0)\n",
    "\n",
    "# combine other workloads (but only one time)\n",
    "# for index, w in enumerate(workloads):\n",
    "#     if (index == 0):\n",
    "#         continue\n",
    "#     print(w)\n",
    "#     print(data_all.shape)\n",
    "#     print(experiments[w].shape)\n",
    "#     data_all = np.concatenate((data_all, experiments[w]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2863703, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into input and output\n",
    "input = data_all[:,0:7]\n",
    "output = data_all[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.concatenate((input[:, 1:2], input[:, 4:7]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6644e-05 0.591229274\n"
     ]
    }
   ],
   "source": [
    "# get normalized input (output stays unnormalized)\n",
    "norm_input = stats.zscore(input, axis=0)\n",
    "\n",
    "print(min(output), max(output))\n",
    "output = output.reshape(-1, 1)\n",
    "\n",
    "norm_input, output, input = shuffle(norm_input, output, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_out_csv(ar, name=None):\n",
    "    if name == None:\n",
    "        name = \"file\"\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(ar)\n",
    "    df.to_csv(index=False, header=False, sep=\" \", path_or_buf=name + \".csv\", float_format=\"%015.6f\") #save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one-hot encoding for operation\n",
    "# data_no_op = np.concatenate((norm_input[:, 0:1], norm_input[:, 2:7]), axis=1)\n",
    "# data_only_ops = np.zeros((len(data_no_op), 8))\n",
    "# for i in range(len(data_no_op)):\n",
    "#     data_only_ops[i,int(input[i,1])] = 1\n",
    "\n",
    "# norm_input = np.concatenate((data_no_op, data_only_ops), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(input[0])):\n",
    "#     print(np.mean(input[:,i]))\n",
    "# for i in range(len(input[0])):\n",
    "    # print(np.std(input[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "training:\n",
    "    1) normalize\n",
    "    2) one-hot encoding for operations\n",
    "    3) multiply outputs by 1e9\n",
    "\n",
    "latency.c:\n",
    "    process_new_features:\n",
    "    1) normalize\n",
    "    2) make prediction\n",
    "    completed_request:\n",
    "    3) add back to prediction how many we subtracted (thus we get the actual prediction class in log2(time))\n",
    "    4) calculate actual prediction class in log2(time) by taking log of diff\n",
    "    5) write the prediction and actual\n",
    "\n",
    "parse.py:\n",
    "    Just parse the actual data. Don't make any modifications.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2320258/765573451.py:7: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(int(math.log2(max(bin_output))), max(bin_output), max(output))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 [5.91229274e+08] [0.59122927]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2320258/765573451.py:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  bin_output[idx] = int(math.log2(o))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.] [29.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import collections\n",
    "\n",
    "# convert to nanoseconds\n",
    "bin_output = output * 1e9\n",
    "\n",
    "print(int(math.log2(max(bin_output))), max(bin_output), max(output))\n",
    "\n",
    "for idx, o in enumerate(bin_output):\n",
    "    bin_output[idx] = int(math.log2(o))\n",
    "\n",
    "bin_output.reshape(-1, 1)\n",
    "print(min(bin_output), max(bin_output))\n",
    "# make minimum 0\n",
    "# make sure to add this difference back in later\n",
    "bin_output = bin_output - min(bin_output)\n",
    "\n",
    "#norm_input, bin_output, (norm_input_sub, bin_output_sub) = equalize_bins(norm_input, bin_output)\n",
    "cnt = collections.Counter(bin_output.ravel())\n",
    "\n",
    "bin_list = []\n",
    "for i in range(32):\n",
    "    bin_list.append(i)\n",
    "\n",
    "class_size = max(bin_output) - min(bin_output) + 1\n",
    "#plt.hist(bin_output, bins=range(0, int(max(cnt.keys())) + 2))\n",
    "plt.bar(cnt.keys(), cnt.values())\n",
    "plt.xticks(list(cnt.keys()))\n",
    "plt.title(\"Histogram of latency buckets\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2863703, 7)\n",
      "(2863703, 1)\n"
     ]
    }
   ],
   "source": [
    "print(norm_input.shape)\n",
    "print(bin_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2320258/3464899621.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  buckets = [0] * int(class_size)\n",
      "/tmp/ipykernel_2320258/3464899621.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  buckets[int(bo)] = buckets[int(bo)] + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57, 23253, 507770, 1226247, 465099, 99223, 489002, 12833, 5488, 8739, 8026, 6662, 6777, 4476, 51]\n",
      "[21513    52     2     1     2    12     2    95   223   140   152   184\n",
      "   180   273 24044]\n"
     ]
    }
   ],
   "source": [
    "buckets = [0] * int(class_size)\n",
    "\n",
    "for index, bo in enumerate(bin_output):\n",
    "    buckets[int(bo)] = buckets[int(bo)] + 1\n",
    "\n",
    "print(buckets)\n",
    "max_bo = max(buckets)\n",
    "\n",
    "buckets = np.array(buckets, dtype=np.float64)\n",
    "buckets /= max_bo\n",
    "buckets = 1.0 / buckets\n",
    "buckets = buckets.astype(np.int32)\n",
    "\n",
    "print(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2320258/89968733.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  if (buckets[int(bo)] > 1):\n",
      "/tmp/ipykernel_2320258/89968733.py:7: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for b in range(buckets[int(bo)] - 1):\n"
     ]
    }
   ],
   "source": [
    "copy_norm_input = []\n",
    "copy_bin_output = []\n",
    "copy_input = []\n",
    "\n",
    "for index, bo in enumerate(bin_output):\n",
    "    if (buckets[int(bo)] > 1):\n",
    "        for b in range(buckets[int(bo)] - 1):\n",
    "            copy_norm_input.append(norm_input[index])\n",
    "            copy_bin_output.append(bin_output[index])\n",
    "            copy_input.append(input[index])\n",
    "    else:\n",
    "        copy_norm_input.append(norm_input[index])\n",
    "        copy_bin_output.append(bin_output[index])\n",
    "        copy_input.append(input[index])\n",
    "\n",
    "norm_input = np.array(copy_norm_input)\n",
    "bin_output = np.array(copy_bin_output)\n",
    "input = np.array(copy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt2 = collections.Counter(bin_output.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(cnt2.keys(), cnt2.values())\n",
    "plt.xticks(list(cnt.keys()))\n",
    "plt.title(\"Histogram of latency buckets\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save old bin output incase we want to change split\n",
    "old_bin_output = bin_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_binary_classification:\n",
    "    bin_output = old_bin_output\n",
    "    print(np.unique(bin_output))\n",
    "    split = 4\n",
    "    bin_output_binary = np.zeros_like(bin_output)\n",
    "    for index, val in enumerate(bin_output):\n",
    "        bin_output_binary[index] = int(val > split)\n",
    "    bin_output = bin_output_binary\n",
    "    print(np.unique(bin_output))\n",
    "    percent_high = sum(bin_output)/len(bin_output)\n",
    "    print(percent_high)\n",
    "    naive_pred = max(percent_high, 1-percent_high) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(file, ap_path):\n",
    "  with open(ap_path, 'wb') as fp:\n",
    "    pickle.dump(file, fp)\n",
    "\n",
    "def load_pickle(ap_path):\n",
    "  with open(ap_path, 'rb') as fp:\n",
    "    return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(norm_input, \"norm_ipnut\")\n",
    "save_pickle(bin_output, \"bin_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, bin_output_train, bin_output_test = train_test_split(norm_input, bin_output, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class latencyPredictor(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(latencyPredictor, self).__init__()\n",
    "        self.layer_1 = torch.nn.Linear(inputSize, 512)\n",
    "        self.layer_2 = torch.nn.Linear(512, 128)\n",
    "        self.layer_3 = torch.nn.Linear(128, 64)\n",
    "        self.layer_out = torch.nn.Linear(64, outputSize)\n",
    "        \n",
    "        self.relu = torch.nn.Sigmoid()\n",
    "        # self.softmax = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        # added softmax to turn our results into preds\n",
    "        # x = self.softmax(x)\n",
    "        # Nevermind! We don't have access to a Softmax layer!\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use multiple gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict2 = {}\n",
    "state_dict2[\"module.layer_1.weight\"] = state_dict[\"module.module.layer_1.weight\"]\n",
    "state_dict2[\"module.layer_2.weight\"] = state_dict[\"module.module.layer_2.weight\"]\n",
    "state_dict2[\"module.layer_3.weight\"] = state_dict[\"module.module.layer_3.weight\"]\n",
    "state_dict2[\"module.layer_out.weight\"] = state_dict[\"module.module.layer_out.weight\"]\n",
    "state_dict2[\"module.layer_1.bias\"] = state_dict[\"module.module.layer_1.bias\"]\n",
    "state_dict2[\"module.layer_2.bias\"] = state_dict[\"module.module.layer_2.bias\"]\n",
    "state_dict2[\"module.layer_3.bias\"] = state_dict[\"module.module.layer_3.bias\"]\n",
    "state_dict2[\"module.layer_out.bias\"] = state_dict[\"module.module.layer_out.bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2319018/188429591.py:2: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  latencyPred = latencyPredictor(norm_input.shape[1], int(class_size))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): latencyPredictor(\n",
       "    (layer_1): Linear(in_features=7, out_features=512, bias=True)\n",
       "    (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (layer_3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (layer_out): Linear(in_features=64, out_features=15, bias=True)\n",
       "    (relu): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do this if you want to load a previous model\n",
    "latencyPred = latencyPredictor(norm_input.shape[1], int(class_size))\n",
    "latencyPred.double()\n",
    "latencyPred = torch.nn.DataParallel(latencyPred)\n",
    "latencyPred.to(device)\n",
    "state_dict = torch.load(\"saved/model.pt\")\n",
    "latencyPred.load_state_dict(state_dict2)\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "latencyPred.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): DataParallel(\n",
       "    (module): latencyPredictor(\n",
       "      (layer_1): Linear(in_features=7, out_features=512, bias=True)\n",
       "      (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (layer_3): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (layer_out): Linear(in_features=64, out_features=15, bias=True)\n",
       "      (relu): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latencyPred.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_560873/1766825350.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  latencyPred = latencyPredictor(norm_input.shape[1], int(class_size))\n"
     ]
    }
   ],
   "source": [
    "# latencyPred = latencyPredictor(input.shape[1], 1)\n",
    "print(class_size)\n",
    "if do_binary_classification:\n",
    "    class_size = 2\n",
    "latencyPred = latencyPredictor(norm_input.shape[1], int(class_size))\n",
    "latencyPred.double()\n",
    "torch.set_num_threads(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): DataParallel(\n",
       "    (module): latencyPredictor(\n",
       "      (layer_1): Linear(in_features=7, out_features=512, bias=True)\n",
       "      (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (layer_3): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (layer_out): Linear(in_features=64, out_features=15, bias=True)\n",
       "      (relu): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criterion = torch.nn.MSELoss()\n",
    "print(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "latencyPred = torch.nn.DataParallel(latencyPred)\n",
    "optimizer = torch.optim.SGD(latencyPred.parameters(), lr=0.01, momentum=0.961)\n",
    "latencyPred.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def plot_loss(epochs, losses, tests, save):\n",
    "    clear_output(wait=True)\n",
    "    fig, ax1 = plt.subplots(figsize =(10, 4))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(epochs, losses, 'b-')\n",
    "    ax2.plot(epochs, tests, 'g-')\n",
    "    custom_lines = [Line2D([0], [0], color='b', lw=4),\n",
    "                Line2D([0], [0], color='g', lw=4)]\n",
    "    plt.legend(custom_lines, ['Loss', \"Accuracy\"])\n",
    "    if save:\n",
    "        plt.savefig(\"loss-acc.png\", dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "def plot_all(epochs, losses, tests, correct_dist_idx, labels):\n",
    "    clear_output(wait=True)\n",
    "    fig, axs = plt.subplots(4,1,figsize =(10, 16))\n",
    "    ax2 = axs[0].twinx()\n",
    "    axs[0].plot(epochs, losses, 'b-')\n",
    "    ax2.plot(epochs, tests, 'g-')\n",
    "    \n",
    "    correct_dist = []\n",
    "    incorrect_dist = []\n",
    "    correct_ones = np.zeros(bin_output.shape[0], dtype = int)\n",
    "    incorrect_ones = np.zeros(bin_output.shape[0], dtype = int)\n",
    "    for idx, answer in enumerate(correct_dist_idx):\n",
    "        if (answer.item()):\n",
    "            correct_dist.append(int(labels[idx]))\n",
    "            correct_ones[int(labels[idx])] = correct_ones[int(labels[idx])] + 1\n",
    "        else:\n",
    "            incorrect_dist.append(int(labels[idx]))\n",
    "            incorrect_ones[int(labels[idx])] = incorrect_ones[int(labels[idx])] + 1\n",
    "    \n",
    "    correct_dist = np.array(correct_dist)\n",
    "    incorrect_dist = np.array(incorrect_dist)\n",
    "\n",
    "    print(len(correct_dist_idx), correct_dist.shape, incorrect_dist.shape)\n",
    "    print(correct_ones)\n",
    "    print(incorrect_ones)\n",
    "\n",
    "    bin_list = range(int(class_size))\n",
    "    axs[1].set_yscale(\"log\")\n",
    "    axs[1].hist(correct_dist, bin_list)\n",
    "    axs[2].set_yscale(\"log\")\n",
    "    axs[2].hist(incorrect_dist, bin_list)\n",
    "    axs[3].set_yscale(\"log\")\n",
    "    axs[3].hist(bin_output, bin_list)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = torch.DoubleTensor(input_train).to(device)\n",
    "# labels = torch.DoubleTensor(bin_output)\n",
    "bin_output_train = torch.LongTensor(bin_output_train).to(device)\n",
    "\n",
    "input_test = torch.DoubleTensor(input_test).to(device)\n",
    "bin_output_test = torch.LongTensor(bin_output_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import plot\n",
    "import collections.abc\n",
    "\n",
    "epochs = []\n",
    "losses = []\n",
    "tests = []\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "\n",
    "for epoch in range(150): # 1000\n",
    "\n",
    "    batch_test = []\n",
    "    batch_loss = []\n",
    "\n",
    "    for batch in range(0, input_train.shape[0], batch_size):\n",
    "        labels = torch.squeeze(bin_output_train[batch:batch+batch_size].to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = latencyPred(input_train[batch:batch+batch_size].to(device))\n",
    "        #print(outputs.shape)\n",
    "        with torch.no_grad():\n",
    "            _, predictions = torch.max(outputs.data, 1)\n",
    "            predictions.to(device)\n",
    "            #print(\"Number of predicted classes: \", len(np.unique(predictions)))\n",
    "            num_correct = (predictions.to(\"cpu\") == labels.to(\"cpu\")).sum().item()\n",
    "\n",
    "            batch_test.append(num_correct / outputs.shape[0] * 100)\n",
    "            correct_dist_idx = (predictions == labels)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        batch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    labels = torch.squeeze(bin_output_test)\n",
    "    outputs = latencyPred(input_test)\n",
    "    _, predictions = torch.max(outputs.data, 1)\n",
    "    predictions.to(device)\n",
    "    num_correct = (predictions.to(\"cpu\") == labels.to(\"cpu\")).sum().item()\n",
    "    test_acc = num_correct / outputs.shape[0] * 100\n",
    "\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    epochs.append(epoch)\n",
    "    losses.append(loss.item())\n",
    "    tests.append(test_acc)\n",
    "    \n",
    "    plot_loss(epochs, losses, tests, epoch==num_epoch-1)\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, losses[-1]))\n",
    "    print('correct predictions {}'.format(tests[-1]))\n",
    "\n",
    "plot_all(epochs, losses, tests, correct_dist_idx, labels)\n",
    "np.save(\"saved/pred\", predictions.cpu())\n",
    "np.save(\"saved/label\", labels.cpu())\n",
    "\n",
    "torch.save(latencyPred.state_dict(), \"saved/model.pt\")\n",
    "\n",
    "print(f\"Final accuracy: {tests[-1]}%\")\n",
    "if do_binary_classification and tests[-1] > naive_pred:\n",
    "    print(f\"We do a lil bit of learning, {tests[-1] - naive_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.04 GiB. GPU 0 has a total capacity of 47.53 GiB of which 4.91 GiB is free. Process 2317924 has 41.40 GiB memory in use. Including non-PyTorch memory, this process has 1.21 GiB memory in use. Of the allocated memory 974.44 MiB is allocated by PyTorch, and 3.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mlatencyPred\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m soft_predictions \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mspecial\u001b[38;5;241m.\u001b[39msoftmax(output_predictions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/model3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/model3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/model3/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:183\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m ({},)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[1;32m    185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, module_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/model3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/model3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/model3/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:183\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m ({},)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[1;32m    185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, module_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/model3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/model3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m, in \u001b[0;36mlatencyPredictor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_2(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/model3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/model3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/model3/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.04 GiB. GPU 0 has a total capacity of 47.53 GiB of which 4.91 GiB is free. Process 2317924 has 41.40 GiB memory in use. Including non-PyTorch memory, this process has 1.21 GiB memory in use. Of the allocated memory 974.44 MiB is allocated by PyTorch, and 3.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "output_predictions = latencyPred(input_test)\n",
    "soft_predictions = scipy.special.softmax(output_predictions.cpu().detach().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_predictions = [sum(i * value for i, value in enumerate(array)) for array in soft_predictions]\n",
    "bin_predictions = np.array(bin_predictions).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = abs(bin_predictions - bin_output_test.cpu().detach().numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6683818696238896\n",
      "1.4212972736515548\n",
      "1.1921817284506397\n",
      "0.5209042382981705\n"
     ]
    }
   ],
   "source": [
    "# 4-feature model using 33% to test from all workloads\n",
    "print(np.mean(diffs))\n",
    "print(np.mean(diffs**2))\n",
    "print(np.sqrt(np.mean(diffs**2)))\n",
    "print(np.mean(diffs == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.5799,   3.9366,   4.4724,  ...,  -3.0395,  -4.5864, -14.2996],\n",
       "        [-12.3283,  -2.6147,   5.0100,  ...,  -2.8761,  -4.0050, -17.3142],\n",
       "        [ -6.3046,   1.4700,   4.2468,  ...,  -4.3976,  -4.5011, -16.6058],\n",
       "        ...,\n",
       "        [ -2.3788,  -1.9821,   2.4508,  ...,  -4.6448,  -6.0121, -19.0162],\n",
       "        [-11.1532,  -7.3834,   1.0462,  ...,  -5.0560,  -5.1637, -15.9855],\n",
       "        [ -2.3788,  -1.9821,   2.4508,  ...,  -4.6448,  -6.0121, -19.0162]],\n",
       "       dtype=torch.float64, grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latencyPred.eval()\n",
    "latencyPred(torch.DoubleTensor(norm_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def layers_to_csv(layer, num):\n",
    "    w_np = layer.cpu().state_dict()['weight'].numpy()\n",
    "    b_np = layer.cpu().state_dict()['bias'].numpy()\n",
    "    df = pd.DataFrame(w_np) #convert to a dataframe\n",
    "    df.to_csv(index=False, header=False, sep=\" \", path_or_buf=f\"torch_model_new/linear{num}_w.csv\", float_format=\"%015.6f\") #save to file\n",
    "    df = pd.DataFrame(b_np) #convert to a dataframe\n",
    "    df.to_csv(index=False, header=False, sep=\" \", path_or_buf=f\"torch_model_new/linear{num}_b.csv\", float_format=\"%015.6f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_to_csv(latencyPred.module.layer_1, 0)\n",
    "layers_to_csv(latencyPred.module.layer_2, 1)\n",
    "layers_to_csv(latencyPred.module.layer_3, 2)\n",
    "layers_to_csv(latencyPred.module.layer_out, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
