{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 20:11:26,913\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-05-24 20:11:28,539\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "from ray import tune\n",
    "\n",
    "print(os.cpu_count())\n",
    "\n",
    "# workloads = [\"readseq\"]#, \"readrandomwriterandom\", \"mixgraph\", \"updaterandom\"] #[\"fileserver\", \"mixgraph\", \"oltp\", \"rwrandom\", \"readseq\", \"readwhilewriting\", \"varmail\", \"webserver\"]\n",
    "\n",
    "# accuracy as comparison of distribuitions\n",
    "# comparitive analysis against table base[HP], cart model[CMU], decision tree,\n",
    "# \n",
    "# -Plan-\n",
    "# Send decision tree graph\n",
    "# let's put latency in the buckets and predict the buckets\n",
    "# - powers of 2\n",
    "# - ?\n",
    "# differnt hw's\n",
    "    # mq-deadline ? setting all deadlines with predictions\n",
    "    # cache the I/O?\n",
    "    # accuracy is based not the class of buckets how far from correct bucket\n",
    "\n",
    "############### FEATURES ##################\n",
    "# 0. issue time to driver - inter-arrival time use it - time diff between two consecutive accesses\n",
    "# 1. operation type\n",
    "# 2. abs(LBA diffs)\n",
    "# 3. time diff between completions\n",
    "# 4. tag\n",
    "# 5. size - length of the I/O operation\n",
    "# 6. queue size\n",
    "# 7. Latency\n",
    "\n",
    "#-> Backtrack the decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "workloads = [\"readseq0\", \"readseq1\", \"readseq2\", \"readseq3\", \"readwhilewriting0\", \"readwhilewriting1\", \"readreverse0\", \"readrandomwriterandom0\", \"readrandom0\", \"mixgraph0\", \"fillseq0\", \"fillseq1\", \"fill100k0\", \"fill100k1\"]\n",
    "config = {\"lr\" : 0.01, \"momentum\" : 0.90}\n",
    "num_epoch = 50\n",
    "do_binary_classification = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {}\n",
    "for w in workloads:\n",
    "    # print(\"reading data for\", w)\n",
    "    data = np.loadtxt(\"data/\" + w + \".csv\",\n",
    "                      dtype=np.double, skiprows=1, delimiter=\",\")\n",
    "    experiments[w] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "combined_data = defaultdict(list)\n",
    "for workload, values in experiments.items():\n",
    "    prefix = ''.join(filter(str.isalpha, workload))\n",
    "    combined_data[prefix].extend(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(values) for values in combined_data.values())\n",
    "def duplicate_to_match_length(data, target_length):\n",
    "    if len(data) == 0:\n",
    "        return []\n",
    "    repeated_data = (data * (target_length // len(data))) + data[:target_length % len(data)]\n",
    "    return repeated_data\n",
    "\n",
    "equalized_data = {key: duplicate_to_match_length(values, max_length) for key, values in combined_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['readseq', 'readwhilewriting', 'readreverse', 'readrandomwriterandom', 'readrandom', 'mixgraph', 'fillseq', 'fillk'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equalized_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, key in enumerate(equalized_data.keys()):\n",
    "        equalized_data[key] = np.hstack((equalized_data[key], np.zeros((len(equalized_data[key]), 1))))\n",
    "        equalized_data[key][:,-1] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = []\n",
    "for values in equalized_data.values():\n",
    "    data_all.extend(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = np.array(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1159888, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into input and output\n",
    "input = data_all[:,0:-1]\n",
    "output = data_all[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.concatenate((input[:, 0:3], input[:, 4:6]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 7.0\n"
     ]
    }
   ],
   "source": [
    "# get normalized input (output stays unnormalized)\n",
    "norm_input = stats.zscore(input, axis=0)\n",
    "\n",
    "print(min(output), max(output))\n",
    "output = output.reshape(-1, 1)\n",
    "\n",
    "norm_input, output, input = shuffle(norm_input, output, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = np.unique(output)\n",
    "bin_output = np.zeros((len(output), len(categories)))\n",
    "for i, value in enumerate(output):\n",
    "    index = np.where(categories == value)[0][0]\n",
    "    bin_output[i, index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_out_csv(ar, name=None):\n",
    "    if name == None:\n",
    "        name = \"file\"\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(ar)\n",
    "    df.to_csv(index=False, header=False, sep=\" \", path_or_buf=name + \".csv\", float_format=\"%015.6f\") #save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0058691436979165235\n",
      "2.353178927620598\n",
      "1619459.160498255\n",
      "16.327928213758568\n",
      "81.25199674451326\n",
      "\n",
      "0.15204302763446695\n",
      "2.241893034781976\n",
      "4724708.014463893\n",
      "4.708433207358461\n",
      "219.24495606131507\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(input[0])):\n",
    "    print(np.mean(input[:,i]))\n",
    "\n",
    "print()\n",
    "\n",
    "for i in range(len(input[0])):\n",
    "    print(np.std(input[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1159888, 5)\n",
      "(1159888, 8)\n"
     ]
    }
   ],
   "source": [
    "print(norm_input.shape)\n",
    "print(bin_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_test, bin_output_train, bin_output_test = train_test_split(norm_input, bin_output, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class latencyPredictor(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(latencyPredictor, self).__init__()\n",
    "        self.layer_1 = torch.nn.Linear(inputSize, 512)\n",
    "        self.layer_2 = torch.nn.Linear(512, 128)\n",
    "        self.layer_3 = torch.nn.Linear(128, 64)\n",
    "        self.layer_out = torch.nn.Linear(64, outputSize)\n",
    "        \n",
    "        self.relu = torch.nn.Sigmoid()\n",
    "        # self.softmax = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        # added softmax to turn our results into preds\n",
    "        # x = self.softmax(x)\n",
    "        # Nevermind! We don't have access to a Softmax layer!\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use multiple gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict2 = {}\n",
    "# state_dict2[\"module.layer_1.weight\"] = state_dict[\"module.module.layer_1.weight\"]\n",
    "# state_dict2[\"module.layer_2.weight\"] = state_dict[\"module.module.layer_2.weight\"]\n",
    "# state_dict2[\"module.layer_3.weight\"] = state_dict[\"module.module.layer_3.weight\"]\n",
    "# state_dict2[\"module.layer_out.weight\"] = state_dict[\"module.module.layer_out.weight\"]\n",
    "# state_dict2[\"module.layer_1.bias\"] = state_dict[\"module.module.layer_1.bias\"]\n",
    "# state_dict2[\"module.layer_2.bias\"] = state_dict[\"module.module.layer_2.bias\"]\n",
    "# state_dict2[\"module.layer_3.bias\"] = state_dict[\"module.module.layer_3.bias\"]\n",
    "# state_dict2[\"module.layer_out.bias\"] = state_dict[\"module.module.layer_out.bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): latencyPredictor(\n",
       "    (layer_1): Linear(in_features=5, out_features=512, bias=True)\n",
       "    (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (layer_3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (layer_out): Linear(in_features=64, out_features=8, bias=True)\n",
       "    (relu): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do this if you want to load a previous model\n",
    "latencyPred = latencyPredictor(norm_input.shape[1], int(class_size))\n",
    "latencyPred.double()\n",
    "latencyPred = torch.nn.DataParallel(latencyPred)\n",
    "latencyPred.to(device)\n",
    "state_dict = torch.load(\"saved/model.pt\")\n",
    "latencyPred.load_state_dict(state_dict)\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "latencyPred.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): latencyPredictor(\n",
       "    (layer_1): Linear(in_features=5, out_features=512, bias=True)\n",
       "    (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (layer_3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (layer_out): Linear(in_features=64, out_features=8, bias=True)\n",
       "    (relu): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latencyPred.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latencyPred = latencyPredictor(input.shape[1], 1)\n",
    "print(class_size)\n",
    "if do_binary_classification:\n",
    "    class_size = 2\n",
    "latencyPred = latencyPredictor(norm_input.shape[1], int(class_size))\n",
    "latencyPred.double()\n",
    "torch.set_num_threads(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = torch.nn.MSELoss()\n",
    "print(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "latencyPred = torch.nn.DataParallel(latencyPred)\n",
    "optimizer = torch.optim.SGD(latencyPred.parameters(), lr=0.01, momentum=0.961)\n",
    "latencyPred.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def plot_loss(epochs, losses, tests, save):\n",
    "    clear_output(wait=True)\n",
    "    fig, ax1 = plt.subplots(figsize =(10, 4))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(epochs, losses, 'b-')\n",
    "    ax2.plot(epochs, tests, 'g-')\n",
    "    custom_lines = [Line2D([0], [0], color='b', lw=4),\n",
    "                Line2D([0], [0], color='g', lw=4)]\n",
    "    plt.legend(custom_lines, ['Loss', \"Accuracy\"])\n",
    "    if save:\n",
    "        plt.savefig(\"loss-acc.png\", dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "def plot_all(epochs, losses, tests, correct_dist_idx, labels):\n",
    "    clear_output(wait=True)\n",
    "    fig, axs = plt.subplots(4,1,figsize =(10, 16))\n",
    "    ax2 = axs[0].twinx()\n",
    "    axs[0].plot(epochs, losses, 'b-')\n",
    "    ax2.plot(epochs, tests, 'g-')\n",
    "    \n",
    "    correct_dist = []\n",
    "    incorrect_dist = []\n",
    "    correct_ones = np.zeros(bin_output.shape[0], dtype = int)\n",
    "    incorrect_ones = np.zeros(bin_output.shape[0], dtype = int)\n",
    "    for idx, answer in enumerate(correct_dist_idx):\n",
    "        if (answer.item()):\n",
    "            correct_dist.append(int(labels[idx]))\n",
    "            correct_ones[int(labels[idx])] = correct_ones[int(labels[idx])] + 1\n",
    "        else:\n",
    "            incorrect_dist.append(int(labels[idx]))\n",
    "            incorrect_ones[int(labels[idx])] = incorrect_ones[int(labels[idx])] + 1\n",
    "    \n",
    "    correct_dist = np.array(correct_dist)\n",
    "    incorrect_dist = np.array(incorrect_dist)\n",
    "\n",
    "    print(len(correct_dist_idx), correct_dist.shape, incorrect_dist.shape)\n",
    "    print(correct_ones)\n",
    "    print(incorrect_ones)\n",
    "\n",
    "    bin_list = range(int(class_size))\n",
    "    axs[1].set_yscale(\"log\")\n",
    "    axs[1].hist(correct_dist, bin_list)\n",
    "    axs[2].set_yscale(\"log\")\n",
    "    axs[2].hist(incorrect_dist, bin_list)\n",
    "    axs[3].set_yscale(\"log\")\n",
    "    axs[3].hist(bin_output, bin_list)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = torch.DoubleTensor(input_train).to(device)\n",
    "# labels = torch.DoubleTensor(bin_output)\n",
    "bin_output_train = torch.LongTensor(bin_output_train).to(device)\n",
    "\n",
    "input_test = torch.DoubleTensor(input_test).to(device)\n",
    "bin_output_test = torch.LongTensor(bin_output_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import plot\n",
    "import collections.abc\n",
    "\n",
    "epochs = []\n",
    "losses = []\n",
    "tests = []\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "\n",
    "for epoch in range(300): # 1000\n",
    "\n",
    "    batch_test = []\n",
    "    batch_loss = []\n",
    "\n",
    "    for batch in range(0, input_train.shape[0], batch_size):\n",
    "        labels = torch.squeeze(bin_output_train[batch:batch+batch_size].to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = latencyPred(input_train[batch:batch+batch_size].to(device))\n",
    "        #print(outputs.shape)\n",
    "        with torch.no_grad():\n",
    "            _, predictions = torch.max(outputs.data, 1)\n",
    "            predictions.to(device)\n",
    "            #print(\"Number of predicted classes: \", len(np.unique(predictions)))\n",
    "            num_correct = (predictions.to(\"cpu\") == labels.to(\"cpu\")).sum().item()\n",
    "\n",
    "            batch_test.append(num_correct / outputs.shape[0] * 100)\n",
    "            correct_dist_idx = (predictions == labels)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        batch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    labels = torch.squeeze(bin_output_test)\n",
    "    outputs = latencyPred(input_test)\n",
    "    _, predictions = torch.max(outputs.data, 1)\n",
    "    predictions.to(device)\n",
    "    num_correct = (predictions.to(\"cpu\") == labels.to(\"cpu\")).sum().item()\n",
    "    test_acc = num_correct / outputs.shape[0] * 100\n",
    "\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    epochs.append(epoch)\n",
    "    losses.append(loss.item())\n",
    "    tests.append(test_acc)\n",
    "    \n",
    "    plot_loss(epochs, losses, tests, epoch==num_epoch-1)\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, losses[-1]))\n",
    "    print('correct predictions {}'.format(tests[-1]))\n",
    "\n",
    "plot_all(epochs, losses, tests, correct_dist_idx, labels)\n",
    "np.save(\"saved/pred\", predictions.cpu())\n",
    "np.save(\"saved/label\", labels.cpu())\n",
    "\n",
    "torch.save(latencyPred.state_dict(), \"saved/model.pt\")\n",
    "\n",
    "print(f\"Final accuracy: {tests[-1]}%\")\n",
    "if do_binary_classification and tests[-1] > naive_pred:\n",
    "    print(f\"We do a lil bit of learning, {tests[-1] - naive_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_outputs = bin_output_test.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_predictions = latencyPred(input_test)\n",
    "soft_predictions = scipy.special.softmax(output_predictions.cpu().detach().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((382764, 8), (382764, 8))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(bin_outputs), np.shape(soft_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros((class_size, class_size))\n",
    "counts = np.zeros(class_size)\n",
    "accuracies = np.zeros(class_size)\n",
    "\n",
    "# Populate the confusion matrix\n",
    "for t, p in zip(bin_outputs, soft_predictions):\n",
    "    t_cls = np.argmax(t)\n",
    "    counts[t_cls] += 1\n",
    "    if (t_cls == np.argmax(p)):\n",
    "        accuracies[t_cls] += 1\n",
    "    for cls, prob in enumerate(p):\n",
    "        confusion_matrix[t_cls, cls] += prob\n",
    "\n",
    "for i in range(class_size):\n",
    "    accuracies[i] /= counts[i]\n",
    "    for j in range(class_size):\n",
    "        confusion_matrix[i][j] /= counts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82926989 0.02097129 0.00666753 0.01145999 0.00676833 0.01490659\n",
      "  0.05042564 0.05953074]\n",
      " [0.02393608 0.29007966 0.01790024 0.22108802 0.22057042 0.21895558\n",
      "  0.00372604 0.00374396]\n",
      " [0.00634409 0.00726434 0.92736257 0.02676018 0.00202244 0.02793366\n",
      "  0.0009487  0.00136401]\n",
      " [0.01061211 0.2029426  0.03700933 0.2601592  0.24147547 0.2451546\n",
      "  0.00126318 0.00138351]\n",
      " [0.0061283  0.21848408 0.00810389 0.25725129 0.2655261  0.2422043\n",
      "  0.00099086 0.00131119]\n",
      " [0.01468848 0.20720532 0.03903813 0.25469994 0.23626599 0.24523461\n",
      "  0.00129923 0.0015683 ]\n",
      " [0.06445935 0.00415552 0.00116463 0.0016492  0.00131932 0.00186242\n",
      "  0.55953392 0.36585563]\n",
      " [0.05805909 0.00313989 0.00126894 0.00133135 0.00137794 0.00165176\n",
      "  0.28714384 0.64602719]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86688068, 0.34330234, 0.98765793, 0.22848416, 0.58630177,\n",
       "       0.061686  , 0.41099231, 0.93374021])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# latencyPred = latencyPredictor(input.shape[1], 1)\n",
    "class_size = len(categories)\n",
    "print(class_size)\n",
    "if do_binary_classification:\n",
    "    class_size = 2\n",
    "latencyPred = latencyPredictor(norm_input.shape[1], int(class_size))\n",
    "latencyPred.double()\n",
    "torch.set_num_threads(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = torch.nn.MSELoss()\n",
    "print(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "latencyPred = torch.nn.DataParallel(latencyPred)\n",
    "optimizer = torch.optim.SGD(latencyPred.parameters(), lr=0.01, momentum=0.961)\n",
    "latencyPred.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6683818696238896\n",
      "1.4212972736515548\n",
      "1.1921817284506397\n",
      "0.5209042382981705\n"
     ]
    }
   ],
   "source": [
    "# 4-feature model using 33% to test from all workloads\n",
    "print(np.mean(diffs))\n",
    "print(np.mean(diffs**2))\n",
    "print(np.sqrt(np.mean(diffs**2)))\n",
    "print(np.mean(diffs == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.5799,   3.9366,   4.4724,  ...,  -3.0395,  -4.5864, -14.2996],\n",
       "        [-12.3283,  -2.6147,   5.0100,  ...,  -2.8761,  -4.0050, -17.3142],\n",
       "        [ -6.3046,   1.4700,   4.2468,  ...,  -4.3976,  -4.5011, -16.6058],\n",
       "        ...,\n",
       "        [ -2.3788,  -1.9821,   2.4508,  ...,  -4.6448,  -6.0121, -19.0162],\n",
       "        [-11.1532,  -7.3834,   1.0462,  ...,  -5.0560,  -5.1637, -15.9855],\n",
       "        [ -2.3788,  -1.9821,   2.4508,  ...,  -4.6448,  -6.0121, -19.0162]],\n",
       "       dtype=torch.float64, grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latencyPred.eval()\n",
    "latencyPred(torch.DoubleTensor(norm_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def layers_to_csv(layer, num):\n",
    "    w_np = layer.cpu().state_dict()['weight'].numpy()\n",
    "    b_np = layer.cpu().state_dict()['bias'].numpy()\n",
    "    df = pd.DataFrame(w_np) #convert to a dataframe\n",
    "    df.to_csv(index=False, header=False, sep=\" \", path_or_buf=f\"torch_model_new/linear{num}_w.csv\", float_format=\"%015.6f\") #save to file\n",
    "    df = pd.DataFrame(b_np) #convert to a dataframe\n",
    "    df.to_csv(index=False, header=False, sep=\" \", path_or_buf=f\"torch_model_new/linear{num}_b.csv\", float_format=\"%015.6f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_to_csv(latencyPred.module.layer_1, 0)\n",
    "layers_to_csv(latencyPred.module.layer_2, 1)\n",
    "layers_to_csv(latencyPred.module.layer_3, 2)\n",
    "layers_to_csv(latencyPred.module.layer_out, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
